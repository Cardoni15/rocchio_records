{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from collections import defaultdict, Counter\n",
    "from tqdm import tqdm\n",
    "from langdetect import detect, DetectorFactory\n",
    "import multiprocessing\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# steps for Rocchio Feedback Filter\n",
    "# PROCESS 1 convert the raw lyrics into the concept space.\n",
    "# 1. Create a TFIDF vectorizer\n",
    "# 2. Create a document term matrix using TFIDF vec fit_transform using the raw lyrics. [I think there is an option to lemmatize here]\n",
    "# 3. Complete latent semantic indexing using TruncatedSVD(num components = num comncepts, specifiy the random state)\n",
    "# 4. Fit the document term matrix using TruncatedSVD.fit_transform. THESE ARE YOUR VECTORS FOR SIMILARITY SCORING\n",
    "\n",
    "# PROCESS 2 convert the query into a vector\n",
    "# 1. Convert querry into a raw string\n",
    "# 2. Use the TFIDF vectorizer above to transform the querry\n",
    "# 3. Use the LSI object above to convert the querry into the concept space.\n",
    "\n",
    "# PROCESS 3 execute the search\n",
    "# 1. Find the cosine similarity between the querry and all lyrics\n",
    "# 2. Sort the tracks by similarity\n",
    "# 3. Return the top N tracks to the user.\n",
    "\n",
    "# PROCESS 4 Rochhio Feedback Filtering\n",
    "# 1. Group user feeback by love, no answer, dislike\n",
    "# 2. Calculate the mean for each group\n",
    "# 3. Apply alpha, beta, gamma, and phi to:\n",
    "#       Original search, loves, hates, nuetral\n",
    "# 4. Update the lyric search querry vector and return new results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the notebook into functions.\n",
    "def load_lyrics_data():\n",
    "    \"\"\"\n",
    "    return a dataframe with cleaned lyrics\n",
    "    \"\"\"\n",
    "    temp_path = os.getcwd()\n",
    "    root_path = temp_path.split('/napster_2')[0]\n",
    "    repo_path = '/napster_2/search_functionality/final_merged_data.csv'\n",
    "    data_path = root_path + repo_path\n",
    "    # step 1 import old lyrical data into a dataframe.\n",
    "    lyric_df = pd.read_csv(data_path)\n",
    "    lyric_df = lyric_df[['track_name', 'artist_name', 'track_id','raw_lyrics']]\n",
    "    # drop duplicate instances of the same track.\n",
    "    lyric_df = lyric_df.drop_duplicates(subset='raw_lyrics').reset_index(drop=True)\n",
    "    lyric_df = lyric_df.dropna()\n",
    "    # replace new line character\n",
    "    lyric_df['raw_lyrics'].replace('\\n', ' ',regex=True, inplace=True)\n",
    "    # remove embed text from lyric genius API\n",
    "    lyric_df['raw_lyrics'].replace('[0-9]{1,3}Embed', '', regex=True, inplace=True)\n",
    "    return lyric_df\n",
    "\n",
    "def create_lyric_tfidf(lyric_df, min_df):\n",
    "    \"\"\" \n",
    "    Create a tfidf vectorizer for the track lyrics\n",
    "    \"\"\"\n",
    "    tfidf = TfidfVectorizer(tokenizer=str.split, min_df=min_df)\n",
    "    # fit the TFIDF vectorizer\n",
    "    tfidf.fit(lyric_df['raw_lyrics'])\n",
    "    return tfidf\n",
    "\n",
    "def lsi_lyrics(lyric_df, tfidf, num_concepts):\n",
    "    \"\"\"\n",
    "    fit an LSI object using the lyrics\n",
    "    \"\"\"\n",
    "    lyricTermMat = tfidf.transform(lyric_df['raw_lyrics'])\n",
    "    lsiObj = TruncatedSVD(n_components=num_concepts, random_state=15)\n",
    "    lsiObj.fit(lyricTermMat)\n",
    "    return lsiObj\n",
    "\n",
    "def create_lyric_vecs(lyric_df, lsiObj, tfidf):\n",
    "    \"\"\" \n",
    "    generate the lyric vectors in the concept space\n",
    "    \"\"\"\n",
    "    lyricTermMat = tfidf.transform(lyric_df['raw_lyrics'])\n",
    "    lyric_vecs = lsiObj.transform(lyricTermMat)\n",
    "    return lyric_vecs\n",
    "\n",
    "def create_lyric_dictionary(lyric_df, lyric_vecs):\n",
    "    \"\"\" \n",
    "    input a lyric dataframe and lsi lyric vectors\n",
    "    return a dictionary where the track id is the key\n",
    "    the vector is the value\n",
    "    \"\"\"\n",
    "    # create a dataframe where the track id is the index the docVecs are the rows.\n",
    "    track_vec_dict = defaultdict(list)\n",
    "    track_ids = lyric_df['track_id'].values\n",
    "    track_vec_dict = {track_ids[i]: lyric_vecs[i] for i in range(len(track_ids))}\n",
    "    return track_vec_dict\n",
    "\n",
    "def lsi_on_query(lsiObj, user_query, tfidf):\n",
    "    \"\"\" \n",
    "    Transform the user search string into the concept space\n",
    "    \"\"\"\n",
    "    userVec = tfidf.transform([user_query])\n",
    "    # convert query vec into the concept space\n",
    "    userLsi = lsiObj.transform(userVec)\n",
    "    return userLsi\n",
    "\n",
    "def retrieve_10_tracks(lyric_df, userLsi, lyric_vecs):\n",
    "    \"\"\" \n",
    "    calculate cosine similarity between lyrics and user query\n",
    "    return the top 10 in a dataframe.\n",
    "    \"\"\"\n",
    "    # calculate cosine similarity between every track and the lyric provided.\n",
    "    simVals = cosine_similarity(lyric_vecs, userLsi)\n",
    "    # create a track name, track id, artist name, similarity dataframe\n",
    "    # need to make this a copy so that we do not modify the already stored data\n",
    "    lyric_df['similarity'] = simVals\n",
    "    user_playlist = lyric_df.sort_values(by='similarity', ascending=False)\n",
    "    user_playlist = user_playlist.head(10)[['track_name', 'artist_name', 'track_id']]\n",
    "    # initialize a feedback column and set every row to 0.\n",
    "    user_playlist['feedback'] = 0\n",
    "    return user_playlist\n",
    "\n",
    "def simulate_user_input(user_playlist):\n",
    "    \"\"\" \n",
    "    Simulate user input assign 0,1,2 to user feedback\n",
    "    0 = nuetral\n",
    "    1 = dislike\n",
    "    2 = love\n",
    "    \"\"\"\n",
    "    feedback = [np.random.randint(0,3) for i in range(len(user_playlist))]\n",
    "    user_playlist['feedback'] = feedback\n",
    "    return user_playlist\n",
    "\n",
    "def rocchio_feedback(alpha, beta, gamma, phi, user_playlist, track_vec_dict, userLsi):\n",
    "    \"\"\" \n",
    "    Rochhio Feedback Filtering\n",
    "    1. Group user feeback by love, nuetral, dislike\n",
    "    2. Calculate the mean for each group\n",
    "    3. Apply alpha, beta, gamma, and phi to:\n",
    "           Original search, loves, hates, nuetral\n",
    "    4. Update the lyric search querry vector and return new results!\n",
    "    return an updated query vector to improve search results\n",
    "    \"\"\"\n",
    "    # create a mean vector dict for all 3 states\n",
    "    meanVectDict = defaultdict(list)\n",
    "    # iterate through the three states nuetral[0], dislike[1], love[2]\n",
    "    for i in range(3):\n",
    "        temp_tracks = user_playlist[user_playlist['feedback']==i]\n",
    "        if len(temp_tracks) > 0:\n",
    "            # this means that tracks with this sentiment exist.\n",
    "            # we can go get the track vectors from the track_vec_dict\n",
    "            tempVecs = [track_vec_dict[vec] for vec in temp_tracks['track_id']]\n",
    "            # next we need to calculate the mean vector for this segment\n",
    "            meanVec = np.mean(tempVecs, axis=0)\n",
    "            # add this mean to the mean vect dict. The key is the state.\n",
    "            meanVectDict[i] = meanVec\n",
    "        else:\n",
    "            # if there are no tracks in this state, set its mean to 0\n",
    "            meanVectDict[i] = 0\n",
    "    # calcualte the new query vector by summing all of the mean vectors together\n",
    "    newQueryVec = alpha*userLsi + beta * meanVectDict[2] - gamma * meanVectDict[1] + phi * meanVectDict[0]\n",
    "    return newQueryVec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cardoni/Library/Python/3.8/lib/python/site-packages/sklearn/feature_extraction/text.py:516: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# All functions from scratch.\n",
    "user_query =  'Jealousy, turning saints into the sea Swimming through sick lullabies Choking on your alibis'\n",
    "# load in lyrics dataframe\n",
    "lyric_df = load_lyrics_data()\n",
    "# create a tfidf vectorizer object\n",
    "tfidf = create_lyric_tfidf(lyric_df, 10)\n",
    "# create a latent semantic indexing object\n",
    "lsiObj = lsi_lyrics(lyric_df, tfidf, 100)\n",
    "# convert the lyrics into content vectors\n",
    "lyric_vecs = create_lyric_vecs(lyric_df, lsiObj, tfidf)\n",
    "# create a dictionary mapping track id to content vector\n",
    "track_vec_dict = create_lyric_dictionary(lyric_df, lyric_vecs)\n",
    "# convert a user string query into the concept space\n",
    "userLsi = lsi_on_query(lsiObj, user_query, tfidf)\n",
    "# create a user playlist and return a dataframe\n",
    "user_playlist = retrieve_10_tracks(lyric_df, userLsi, lyric_vecs)\n",
    "# simulate user input while we are not connected to the GUI\n",
    "user_playlist = simulate_user_input(user_playlist)\n",
    "# Apply rocchio feedback filter to generate a better query\n",
    "rocchioSearch = rocchio_feedback(1.0, 0.75, 0.25, 0.5, user_playlist, track_vec_dict, userLsi)\n",
    "# generate a new user playlist with the updated search\n",
    "user_playlist = retrieve_10_tracks(lyric_df, rocchioSearch, lyric_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lsi_dict_pickle(track_vec_dict):\n",
    "    pickle.dump(track_vec_dict, open('lsi_vec_dict.p', 'wb'))\n",
    "def create_lsi_obj_pickle(lsiObj):\n",
    "    pickle.dump(lsiObj, open('lsi_obj.p', 'wb'))\n",
    "def create_tfidf_obj_pickle(tfidf):\n",
    "    pickle.dump(tfidf, open('tfidf_obj.p', 'wb'))\n",
    "def load_lsi_pickle():\n",
    "    \"\"\" \n",
    "    read in the pickle file containing the fitted\n",
    "    LSI object\n",
    "    \"\"\"\n",
    "    with open('lsi_obj.p', 'rb') as lsi_file:\n",
    "        lsiObj = pickle.load(lsi_file)\n",
    "        lsi_file.close()\n",
    "        return lsiObj\n",
    "def load_tfidf_pickle():\n",
    "    \"\"\" \n",
    "    read in the pickle file containing the fitted\n",
    "    TFIDF object\n",
    "    \"\"\"\n",
    "    with open('tfidf_obj.p', 'rb') as tfidf_file:\n",
    "        tfidf = pickle.load(tfidf_file)\n",
    "        tfidf_file.close()\n",
    "        return tfidf\n",
    "def load_lsi_dict_pickle():\n",
    "    \"\"\" \n",
    "    read in the pickle file containing the fitted\n",
    "    TFIDF object\n",
    "    \"\"\"\n",
    "    with open('lsi_vec_dict.p', 'rb') as lyric_file:\n",
    "        lryicVecs = pickle.load(lyric_file)\n",
    "        lyric_file.close()\n",
    "        return lryicVecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# production work flow (bypass creating new objects by reading in their pickle instead)\n",
    "user_query =  'Jealousy, turning saints into the sea Swimming through sick lullabies Choking on your alibis'\n",
    "# load in lyrics dataframe\n",
    "lyric_df = pd.read_csv('track_artist_id_df')\n",
    "# create a tfidf vectorizer object\n",
    "tfidf = load_tfidf_pickle()\n",
    "# create a latent semantic indexing object\n",
    "lsiObj = load_lsi_pickle()\n",
    "# convert the lyrics into content vectors This is stored in the dictionary\n",
    "lyric_vecs = np.array(list(track_vec_dict.values()))\n",
    "# create a dictionary mapping track id to content vector\n",
    "track_vec_dict = load_lsi_dict_pickle()\n",
    "# convert a user string query into the concept space\n",
    "userLsi = lsi_on_query(lsiObj, user_query, tfidf)\n",
    "# create a user playlist and return a dataframe\n",
    "user_playlist = retrieve_10_tracks(lyric_df, userLsi, lyric_vecs)\n",
    "# simulate user input while we are not connected to the GUI\n",
    "user_playlist = simulate_user_input(user_playlist)\n",
    "# Apply rocchio feedback filter to generate a better query\n",
    "rocchioSearch = rocchio_feedback(1.0, 0.75, 0.25, 0.5, user_playlist, track_vec_dict, userLsi)\n",
    "# generate a new user playlist with the updated search\n",
    "user_playlist = retrieve_10_tracks(lyric_df, rocchioSearch, lyric_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Napster2_Rocchio_Feedback():\n",
    "    \"\"\" \n",
    "    Object for containing all relevant Rocchio Search functionality\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.query = None\n",
    "        self.user_playlist = None\n",
    "        self.main_path = self.base_path()\n",
    "        self.lyric_vec_dict = self.load_lsi_dict_pickle()\n",
    "        self.lyric_vecs = np.array(list(self.lyric_vec_dict.values()))\n",
    "        self.lsiObj = self.load_lsi_pickle()\n",
    "        self.tfidf = self.load_tfidf_pickle()\n",
    "        self.all_tracks_df = pd.read_csv(self.main_path+'track_artist_id_df')\n",
    "    \n",
    "    def base_path(self):\n",
    "            temp_path = os.getcwd()\n",
    "            root_path = temp_path.split('/napster_2')[0]\n",
    "            repo_path = '/napster_2/search_functionality/'\n",
    "            return root_path + repo_path\n",
    "\n",
    "    def userSearch(self, user_query):\n",
    "        \"\"\" \n",
    "        Transform the user search string into the concept space\n",
    "        \"\"\"\n",
    "        userVec = self.tfidf.transform([user_query])\n",
    "        # convert query vec into the concept space\n",
    "        userLsi = self.lsiObj.transform(userVec)\n",
    "        self.query = userLsi\n",
    "\n",
    "    def load_lsi_pickle(self):\n",
    "        \"\"\" \n",
    "        read in the pickle file containing the fitted\n",
    "        LSI object\n",
    "        \"\"\"\n",
    "        temp_path = self.main_path + 'lsi_obj.p'\n",
    "        with open(temp_path, 'rb') as lsi_file:\n",
    "            lsiObj = pickle.load(lsi_file)\n",
    "            lsi_file.close()\n",
    "            return lsiObj\n",
    "    def load_tfidf_pickle(self):\n",
    "        \"\"\" \n",
    "        read in the pickle file containing the fitted\n",
    "        TFIDF object\n",
    "        \"\"\"\n",
    "        temp_path = self.main_path + 'tfidf_obj.p'\n",
    "        with open(temp_path, 'rb') as tfidf_file:\n",
    "            tfidf = pickle.load(tfidf_file)\n",
    "            tfidf_file.close()\n",
    "            return tfidf\n",
    "    def load_lsi_dict_pickle(self):\n",
    "        \"\"\" \n",
    "        read in the pickle file containing the fitted\n",
    "        TFIDF object\n",
    "        \"\"\"\n",
    "        temp_path = self.main_path +'lsi_vec_dict.p' \n",
    "        with open(temp_path, 'rb') as lyric_file:\n",
    "            lryicVecs = pickle.load(lyric_file)\n",
    "            lyric_file.close()\n",
    "            return lryicVecs\n",
    "\n",
    "    def create_user_playlist(self): #lyric_df, userLsi, lyric_vecs):\n",
    "        \"\"\" \n",
    "        calculate cosine similarity between lyrics and user query\n",
    "        return the top 10 in a dataframe.\n",
    "        \"\"\"\n",
    "        # calculate cosine similarity between every track and the lyric provided.\n",
    "        simVals = cosine_similarity(self.lyric_vecs, self.query)\n",
    "        # create a track name, track id, artist name, similarity dataframe\n",
    "        # need to make this a copy so that we do not modify the already stored data\n",
    "        self.all_tracks_df['similarity'] = simVals\n",
    "        self.user_playlist = lyric_df.sort_values(by='similarity', ascending=False).head(10)[['track_name', 'artist_name', 'track_id']]\n",
    "        self.user_playlist['feedback'] = 0\n",
    "\n",
    "    def return_top_10_tracks(self):\n",
    "        \"\"\" \n",
    "        return the top 10 tracks based on cosine similarity\n",
    "        \"\"\"\n",
    "        return self.user_playlist\n",
    "\n",
    "    def apply_feedback(self, feedback_series):\n",
    "        \"\"\" \n",
    "        User input assign 0,1,2 to user feedback\n",
    "        0 = nuetral\n",
    "        1 = dislike\n",
    "        2 = love\n",
    "        \"\"\"\n",
    "        self.user_playlist['feedback'] = feedback_series\n",
    "\n",
    "    def rocchio_feedback(self, alpha=1.0, beta=0.75, gamma=0.25, phi=0.5):#, user_playlist, track_vec_dict, userLsi):\n",
    "        \"\"\" \n",
    "        Rochhio Feedback Filtering\n",
    "        1. Group user feeback by love, nuetral, dislike\n",
    "        2. Calculate the mean for each group\n",
    "        3. Apply alpha, beta, gamma, and phi to:\n",
    "            Original search, loves, hates, nuetral\n",
    "        4. Update the lyric search querry vector and return new results!\n",
    "        return an updated query vector to improve search results\n",
    "        \"\"\"\n",
    "        # create a mean vector dict for all 3 states\n",
    "        meanVectDict = defaultdict(list)\n",
    "        # iterate through the three states nuetral[0], dislike[1], love[2]\n",
    "        for i in range(3):\n",
    "            temp_tracks = self.user_playlist[self.user_playlist['feedback']==i]\n",
    "            if len(temp_tracks) > 0:\n",
    "                # this means that tracks with this sentiment exist.\n",
    "                # we can go get the track vectors from the track_vec_dict\n",
    "                tempVecs = [self.lyric_vec_dict[vec] for vec in temp_tracks['track_id']]\n",
    "                # next we need to calculate the mean vector for this segment\n",
    "                meanVec = np.mean(tempVecs, axis=0)\n",
    "                # add this mean to the mean vect dict. The key is the state.\n",
    "                meanVectDict[i] = meanVec\n",
    "            else:\n",
    "                # if there are no tracks in this state, set its mean to 0\n",
    "                meanVectDict[i] = 0\n",
    "        # calcualte the new query vector by summing all of the mean vectors together\n",
    "        newQueryVec = alpha*self.query + beta * meanVectDict[2] - gamma * meanVectDict[1] + phi * meanVectDict[0]\n",
    "        self.query = newQueryVec\n",
    "        # update the search after making a new query vector\n",
    "        self.create_user_playlist()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "myRFF = Napster2_Rocchio_Feedback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "myRFF.userSearch('Jealousy, turning saints into the sea')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_name</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>track_id</th>\n",
       "      <th>feedback</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>69605</th>\n",
       "      <td>On Your Own</td>\n",
       "      <td>Meltt</td>\n",
       "      <td>1jUp1Yu76G1mXzr224YKHb</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        track_name artist_name                track_id  feedback\n",
       "69605  On Your Own       Meltt  1jUp1Yu76G1mXzr224YKHb         0"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myRFF.create_user_playlist()\n",
    "myRFF.apply_feedback([1,2,1,2,1,2,0,1,1,0])\n",
    "myRFF.user_playlist\n",
    "myRFF.rocchio_feedback()\n",
    "pd.DataFrame(myRFF.return_top_10_tracks().iloc[[0]])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
